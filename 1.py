#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö Spotify Tracks —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Pandas
–ó–∞–¥–∞—á–∞: –Ω–∞–π—Ç–∏ –º—É–∑—ã–∫–∞–ª—å–Ω—ã–π –∂–∞–Ω—Ä —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–Ω–µ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å—é
"""
import pandas as pd
import sys
import os
import csv

def inspect_file(filepath):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞"""
    print("=== –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–∞ ===")
    
    # –ü—Ä–æ–≤–µ—Ä–∏–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –≤—Ä—É—á–Ω—É—é
    try:
        with open(filepath, 'r', encoding='utf-8', errors='replace') as f:
            print("–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ —Ñ–∞–π–ª–∞:")
            for i, range(5):
                line = f.readline()
                print(f"–°—Ç—Ä–æ–∫–∞ {i+1}: {line[:200]}...")  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return False
    return True

def load_data_simple(filepath):
    """–ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    print("–ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ—Å—Ç–æ–π –∑–∞–≥—Ä—É–∑–∫–∏...")
    try:
        # –°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–±
        df = pd.read_csv(filepath, encoding='utf-8')
        print(f"‚úÖ –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞: {len(df)} —Å—Ç—Ä–æ–∫")
        return df
    except Exception as e:
        print(f"‚ùå –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        return None

def load_data_robust(filepath):
    """–ù–∞–¥–µ–∂–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    print("–ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–¥–µ–∂–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏...")
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        separators = [',', ';', '\t', '|']
        
        for sep in separators:
            try:
                print(f"–ü—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: '{sep}'")
                df = pd.read_csv(
                    filepath,
                    encoding='utf-8',
                    sep=sep,
                    engine='python',
                    quoting=csv.QUOTE_MINIMAL,
                    error_bad_lines=False,
                    warn_bad_lines=True
                )
                if len(df) > 0:
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{sep}': {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
                    return df
            except Exception as e:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{sep}': {e}")
                continue
        return None
    except Exception as e:
        print(f"‚ùå –ù–∞–¥–µ–∂–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        return None

def load_data_chunks(filepath):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ —á–∞—Å—Ç—è–º"""
    print("–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ —á–∞—Å—Ç—è–º...")
    try:
        chunks = []
        chunk_size = 10000
        
        for i, chunk in enumerate(pd.read_csv(filepath, encoding='utf-8', chunksize=chunk_size, error_bad_lines=False)):
            chunks.append(chunk)
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —á–∞–Ω–∫ {i+1}: {len(chunk)} —Å—Ç—Ä–æ–∫")
            
        df = pd.concat(chunks, ignore_index=True)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ —á–∞—Å—Ç—è–º: {len(df)} —Å—Ç—Ä–æ–∫")
        return df
    except Exception as e:
        print(f"‚ùå –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ —á–∞—Å—Ç—è–º –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        return None

def load_data_final(filepath):
    """–§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏"""
    print("–§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏...")
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º —Ñ–∞–π–ª
    if not inspect_file(filepath):
        return None
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    methods = [
        load_data_simple,
        load_data_robust, 
        load_data_chunks
    ]
    
    for method in methods:
        df = method(filepath)
        if df is not None and len(df) > 0:
            return df
    
    print("‚ùå –í—Å–µ –º–µ—Ç–æ–¥—ã –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å")
    return None

def clean_data(df):
    """–û—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    if df is None:
        return None
        
    print("\n=== –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===")
    print(f"–ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(df):,}")
    print(f"–°—Ç–æ–ª–±—Ü—ã: {list(df.columns)}")
    
    # –ù–∞–π–¥–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å—é –∏ –∂–∞–Ω—Ä–æ–º
    popularity_col = None
    genre_col = None
    
    # –ò—â–µ–º —Å—Ç–æ–ª–±—Ü—ã –ø–æ —Ä–∞–∑–Ω—ã–º –≤–æ–∑–º–æ–∂–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º
    for col in df.columns:
        col_lower = col.lower()
        if 'popular' in col_lower and popularity_col is None:
            popularity_col = col
        if 'genre' in col_lower and genre_col is None:
            genre_col = col
    
    if popularity_col is None:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü —Å –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å—é")
        print("–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:", df.columns.tolist())
        return None
        
    if genre_col is None:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü —Å –∂–∞–Ω—Ä–æ–º")
        print("–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:", df.columns.tolist())
        return None
    
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–æ–ª–±–µ—Ü –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏: '{popularity_col}'")
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–æ–ª–±–µ—Ü –∂–∞–Ω—Ä–∞: '{genre_col}'")
    
    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    initial_count = len(df)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
    df = df[df[popularity_col].notna()]
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø
    df[popularity_col] = pd.to_numeric(df[popularity_col], errors='coerce')
    df = df[df[popularity_col].notna()]
    
    # –û—á–∏—Å—Ç–∫–∞ –∂–∞–Ω—Ä–∞
    df[genre_col] = df[genre_col].fillna('Unknown')
    
    print(f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(df):,}")
    print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∂–∞–Ω—Ä–æ–≤: {df[genre_col].nunique()}")
    
    return df, popularity_col, genre_col

def analyze_popularity_by_genre(df, popularity_col, genre_col):
    """–ê–Ω–∞–ª–∏–∑ —Å—Ä–µ–¥–Ω–µ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –ø–æ –∂–∞–Ω—Ä–∞–º"""
    print("\n=== –ê–Ω–∞–ª–∏–∑ —Å—Ä–µ–¥–Ω–µ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –ø–æ –∂–∞–Ω—Ä–∞–º ===")
    
    # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏:")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ: {df[popularity_col].mean():.2f}")
    print(f"  –ú–µ–¥–∏–∞–Ω–∞: {df[popularity_col].median():.2f}")
    print(f"  –ú–∏–Ω–∏–º—É–º: {df[popularity_col].min():.2f}")
    print(f"  –ú–∞–∫—Å–∏–º—É–º: {df[popularity_col].max():.2f}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ –∂–∞–Ω—Ä–∞–º
    result = df.groupby(genre_col)[popularity_col].agg([
        ('Mean_Popularity', 'mean'),
        ('Count', 'count'),
        ('Std', 'std'),
        ('Min_Popularity', 'min'),
        ('Max_Popularity', 'max')
    ]).reset_index()
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ä–µ–¥–Ω–µ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
    result = result.sort_values('Mean_Popularity', ascending=False)
    
    return result

def main():
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞–Ω–Ω—ã—Ö
    data_file = '/opt/data/database.csv'
    
    if not os.path.exists(data_file):
        data_file = 'database.csv'
    
    if not os.path.exists(data_file):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_file}")
        sys.exit(1)
    
    file_size = os.path.getsize(data_file) / (1024*1024)
    print(f"=== –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö Spotify Tracks ===")
    print(f"üìÅ –§–∞–π–ª: {data_file}")
    print(f"üìä –†–∞–∑–º–µ—Ä: {file_size:.1f} MB")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_data_final(data_file)
    
    if df is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        sys.exit(1)
    
    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    cleaned = clean_data(df)
    if cleaned is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        sys.exit(1)
    
    df_clean, popularity_col, genre_col = cleaned
    
    # –ê–Ω–∞–ª–∏–∑
    result = analyze_popularity_by_genre(df_clean, popularity_col, genre_col)
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "="*60)
    print("üéµ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê")
    print("="*60)
    
    print("\n–¢–æ–ø-10 –∂–∞–Ω—Ä–æ–≤ –ø–æ —Å—Ä–µ–¥–Ω–µ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏:")
    display_df = result.head(10).round(2)
    print(display_df.to_string(index=False))
    
    if len(result) > 0:
        max_genre = result.iloc[0]
        print(f"\nüèÜ –õ–£–ß–®–ò–ô –ñ–ê–ù–†:")
        print(f"   –ñ–∞–Ω—Ä: '{max_genre[genre_col]}'")
        print(f"   –°—Ä–µ–¥–Ω—è—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: {max_genre['Mean_Popularity']:.2f}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–∫–æ–≤: {int(max_genre['Count']):,}")
        print(f"   –î–∏–∞–ø–∞–∑–æ–Ω: {max_genre['Min_Popularity']:.2f} - {max_genre['Max_Popularity']:.2f}")
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_file = 'results/popularity_by_genre.csv'
    os.makedirs('results', exist_ok=True)
    result.to_csv(output_file, index=False, encoding='utf-8')
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    
    return result

if __name__ == '__main__':
    main()
